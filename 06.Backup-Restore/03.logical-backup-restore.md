## Logical Backup and Restore:

A logical backup means backing up logical objects (schemas, tables, procedures, users, data, etc.) rather than physical files (datafiles, control files). It is performed using tools like Oracle Data Pump (introduced in Oracle 10g) or the older Export/Import utilities (`exp`/`imp`).

- Done using Oracle Data Pump (`expdp` for export, `impdp` for import).
- Output is a dump file (`.dmp`) + log file (`.log`).
- Stored in an Oracle Directory Object (must be created beforehand).
- Useful for:
    - Migrating schema(s)/tables between databases.
    - Exporting subsets of data.
    - Platform-independent backups.
- Data pump best for **schema backup** and **table backup** but **not good full database backup** (when full backup imported existing built-in metadata and default schema (like sys, system) conflicted). 
- Not suitable for disaster recovery (since it doesn’t back up control files, redo logs, or system metadata).



### Data Pump Export Modes:
- **Full Mode**: A full database export is specified using the `FULL` parameter.
- **Schema Mode**: A schema export is specified using the `SCHEMAS` parameter. This is the default export mode.
- **Table Mode**: A table mode export is specified using the `TABLES` parameter.
- **Tablespace Mode**: A tablespace export is specified using the `TABLESPACES` parameter.
- **Transportable Tablespace Mode**: A transportable tablespace export is specified using the `TRANSPORT_TABLESPACES` parameter.


### Data Pump Import Modes:
- **Full Import Mode** : A full import is specified using the `FULL` parameter.
- **Schema Mode** : A schema import is specified using the `SCHEMAS` parameter.
- **Table Mode** : A table-mode import is specified using the `TABLES` parameter.
- **Tablespace Mode** : A tablespace-mode import is specified using the `TABLESPACES` parameter.
- **Transportable Tablespace Mode** : A transportable tablespace import is specified using the `TRANSPORT_TABLESPACES` parameter.



### Data Pump Object Types:

1. TABLE
    - The base table definition (columns, datatypes, storage parameters).
2. TABLE/INDEX
    - Indexes created on the table.
3. TABLE/INDEX/STATISTICS/INDEX_STATISTICS
    - Optimizer statistics for the indexes.
    - Helps Oracle generate efficient execution plans.
4. TABLE/STATISTICS/TABLE_STATISTICS
    - Optimizer statistics for the table (row count, block usage, column cardinality).
5. TABLE/TRIGGER
    - Triggers associated with the table.




---
---



### Logical Backup using `expdp`:

_Plan the Backup Scope:_
- Decide what to back up: full database, specific schemas, tables, or tablespaces.
- Common scopes:
    - Full Database: `FULL=Y`
    - Schema(s): SCHEMAS=schema_name1,schema_name2
    - Tables: TABLES=schema_name.table_name
    - Tablespaces: TABLESPACES=tablespace_name



#### 1. Create Directory Object:
```
mkdir -p /home/oracle/backup/expdp
```


```
CREATE OR REPLACE DIRECTORY expdp_dir AS '/home/oracle/backup/expdp';

GRANT READ, WRITE ON DIRECTORY expdp_dir TO system;
```


```
grant datapump_exp_full_database to system;
grant datapump_imp_full_database to system;
```


Or,


_Create Data Pump User:_
```
create user backup_user identified by password;
alter user backup_user quota unlimited on users;
grant connect, resource to backup_user;

GRANT READ, WRITE ON DIRECTORY expdp_dir TO backup_user;
```


```
grant datapump_exp_full_database to backup_user;
grant datapump_imp_full_database to backup_user;
```


_Verify user open or not:_
```
SELECT username, user_id, account_status, last_login FROM dba_users WHERE account_status = 'OPEN';

USERNAME                USER_ID     ACCOUNT_STATUS           LAST_LOGIN
-------------------- ----------     ----------------         -----------------
SYS                           0     OPEN
SYSTEM                        9     OPEN
BACKUP_USER                 107     OPEN
```



```
SELECT username, user_id, account_status, last_login FROM dba_users WHERE USERNAME = 'BACKUP_USER';


USERNAME        USER_ID         ACCOUNT_STATUS      LAST_LOGIN
--------------  ----------      -----------------   --------------
BACKUP_USER     110             OPEN
```



_Check Backup location:_
```
col DIRECTORY_NAME for a20;
col directory_path for a50;

select OWNER, DIRECTORY_NAME, directory_path from dba_directories where directory_name='EXPDP_DIR';

OWNER           DIRECTORY_NAME          DIRECTORY_PATH
-------------   -------------------     -------------------------------
SYS             EXPDP_DIR               /home/oracle/backup/expdp
```



#### HR Schema: 

_Check if HR schema exists:_
```
col username for a20

SELECT username, account_status FROM dba_users WHERE username = 'HR';

USERNAME             ACCOUNT_STATUS
-------------------- --------------------------------
HR                   EXPIRED & LOCKED
```

_Unlock HR Schema:_
```
ALTER USER hr IDENTIFIED BY hr ACCOUNT UNLOCK;
GRANT CONNECT, RESOURCE TO hr;
```


_Check default tablespace for HR:_
```
SELECT username, default_tablespace, temporary_tablespace FROM dba_users WHERE username = 'HR';

USERNAME             DEFAULT_TABLESPACE     TEMPORARY_TABLESPACE
-------------------- -------------------    ----------------------
HR                   SYSAUX                 TEMP
```


_Change Default Tablespace:_
```
ALTER USER hr DEFAULT TABLESPACE users;
ALTER USER hr TEMPORARY TABLESPACE temp;

ALTER USER hr QUOTA UNLIMITED ON users;
```


_Check HR schema tables:_
``` 
SELECT table_name FROM dba_tables WHERE owner = 'HR';

TABLE_NAME
--------------------
COUNTRIES
REGIONS
LOCATIONS
DEPARTMENTS
JOBS
EMPLOYEES
JOB_HISTORY
```


_Check Table of Tablespace:_
```
select tablespace_name from dba_tables where table_name='DEPARTMENTS';

TABLESPACE_NAME
----------------
SYSAUX
```


_Move the Table to a `users` Tablespace:_
```
ALTER TABLE hr.COUNTRIES MOVE TABLESPACE users;
ALTER TABLE hr.REGIONS MOVE TABLESPACE users;
ALTER TABLE hr.LOCATIONS MOVE TABLESPACE users;
ALTER TABLE hr.departments MOVE TABLESPACE users;
ALTER TABLE hr.JOBS MOVE TABLESPACE users;
ALTER TABLE hr.EMPLOYEES MOVE TABLESPACE users;
ALTER TABLE hr.JOB_HISTORY MOVE TABLESPACE users;
```


_Move Indexes (if needed):_
```
SELECT index_name, tablespace_name FROM dba_indexes WHERE table_owner='HR' AND table_name='DEPARTMENTS';

INDEX_NAME              TABLESPACE_NAME
---------------------   ----------------------
DEPT_LOCATION_IX        SYSAUX
DEPT_ID_PK              SYSAUX
```



```
ALTER INDEX hr.DEPT_LOCATION_IX REBUILD TABLESPACE users;
ALTER INDEX hr.DEPT_ID_PK REBUILD TABLESPACE users;
```


_If you don’t have DBA access:_
```
conn hr/hr

select table_name from user_tables;

TABLE_NAME
------------------
COUNTRIES
REGIONS
LOCATIONS
DEPARTMENTS
JOBS
EMPLOYEES
JOB_HISTORY
```






#### 2. Run `expdp` Command:

_Basic syntax:_
```
expdp user/password@service schemas=hr directory=expdp_dir dumpfile=hr_schema.dmp logfile=hr_schema.log logtime=all metrics=yes 
```


_Full Database Export:_
```
expdp system/password@orcl FULL=Y directory=expdp_dir dumpfile=full_db.dmp logfile=full_db_export.log
```


_Parallel Backup (CPUs core x 2): Speed up the export for large databases:_
- `%U` : creates multiple dump files (e.g., full_backup_01.dmp, full_backup_02.dmp). A two digit number incremented between 01-99.
-` %l`, `%L` : This starts off similar to "%U", producing a two digit number between 01-99, but it can extend up to 2147483646, so the resulting file name is not a fixed length.
- `bakup_%T_%L`:  %T for the current date in YYYYMMDD format.

```
expdp system/password@orcl FULL=Y DIRECTORY=expdp_dir DUMPFILE=full_db_backup_%U.dmp logfile=full_db_export.log PARALLEL=4
```


_Schema Export:_
```
expdp system/password@orcl schemas=HR directory=expdp_dir dumpfile=hr_schema.dmp logfile=hr_schema_export.log exclude=statistics
```


_Table Export:_
```
expdp system/password@orcl tables=hr.EMPLOYEES,hr.DEPARTMENTS directory=expdp_dir dumpfile=emp_dept_tables.dmp logfile=emp_dept_tables_export.log
```


_Tablespace Export:_
```
expdp system/password@orcl tablespaces=USERS directory=expdp_dir dumpfile=users_ts.dmp logfile=users_ts_export.log
```



_Compression: Reduce dump file size:_
```
expdp system/password@orcl SCHEMAS=hr DIRECTORY=expdp_dir DUMPFILE=hr_schema_comm.dmp logfile=hr_schema_comm_export.log COMPRESSION=ALL
```



#### 3. Exclude/Include Objects:

_Exclude/Include Objects:_
- view
- statistics
- table_statistics
- index_statistics
- constraint 
- procedure


_Export a schema but exclude statistics:_
```
expdp system/password@orcl schemas=HR directory=expdp_dir dumpfile=hr_schema_no_statistics.dmp logfile=hr_schema_export.log EXCLUDE=STATISTICS
```


_Export a schema but exclude indexes:_
```
expdp system/password@orcl schemas=HR DIRECTORY=expdp_dir DUMPFILE=hr_schema_no_indexes.dmp LOGFILE=hr_schema_no_indexes_export.log EXCLUDE=INDEX
```



_Include Objects: export only tables:_
```
expdp system/password@orcl schemas=HR DIRECTORY=expdp_dir DUMPFILE=hr_schema_tables.dmp LOGFILE=hr_schema_tables_export.log INCLUDE=TABLE
```


```
expdp system/password@orcl schemas=HR DIRECTORY=expdp_dir DUMPFILE=hr_schema_indexes.dmp LOGFILE=hr_schema_indexes_export.log INCLUDE=INDEX
```




---
---





### Logical Restore with `impdp`:

The restore process for a logical backup involves importing the dump file using Oracle Data Pump Import (`impdp`). This is not a physical restore but a logical recreation of objects and data.


_Prepare the Target Database:_
- Ensure the target database is running and has sufficient space in the target tablespaces.
- Create a directory object if not already present. 
- `impdp` **tries to create tables in the same tablespaces** they had in the source DB. If the tablespace does not exist in the target DB → import will fail.
- Create the same tablespaces before import. 



#### 1. Create Directory Object:

```
mkdir -p /home/oracle/backup/expdp
```


```
CREATE OR REPLACE DIRECTORY expdp_dir AS '/home/oracle/backup/expdp';

GRANT READ, WRITE ON DIRECTORY expdp_dir TO system;
```




#### 2. Run `impdp` Command:

_Basic syntax:_
```
impdp user/password@service schemas=hr directory=expdp_dir dumpfile=hr_schema.dmp logfile=hr_schema.log logtime=all metrics=yes
```


_Full Database Import:_
```
impdp system/password@orcl FULL=Y DIRECTORY=expdp_dir DUMPFILE=full_db.dmp LOGFILE=full_db_import.log
```


_Parallel Import:_
```
impdp system/password@orcl FULL=Y DIRECTORY=expdp_dir DUMPFILE=full_db_backup_%U.dmp logfile=full_db_import.log PARALLEL=4
```


_Schema Import:_
```
impdp system/password@orcl schemas=HR directory=expdp_dir dumpfile=hr_schema.dmp logfile=hr_schema_import.log
```



_Table Import:_
```
impdp system/password@orcl tables=hr.EMPLOYEES,hr.DEPARTMENTS directory=expdp_dir dumpfile=emp_dept_tables.dmp logfile=emp_dept_tables_import.log
```


_Tablespace Import:_
- The target database must already have the same tablespaces created. 

```
impdp system/password@orcl tablespaces=users directory=expdp_dir dumpfile=users_ts.dmp logfile=users_ts_import.log 
```



_Import from Compressed Dump:_
- During impdp, Oracle automatically decompresses the dump file.

```
impdp system/password@orcl schemas=hr directory=expdp_dir dumpfile=hr_schema_comm.dmp logfile=hr_schema_comm_import.log 
```




#### 3. Remap Schema: 

_Syntax:_
```
REMAP_SCHEMA=source_schema:target_schema
```


```
impdp system/password@orcl SCHEMAS=hr REMAP_SCHEMA=hr:hr_new DIRECTORY=expdp_dir DUMPFILE=hr_schema.dmp LOGFILE=hr_schema_remap_import.log
```



```
SELECT username, user_id, account_status, last_login FROM dba_users WHERE USERNAME = 'HR_NEW';

USERNAME            USER_ID         ACCOUNT_STATUS              LAST_LOGIN
-----------         ------------    -----------------           -------------------
HR_NEW              108             OPEN                        
```


```
conn hr_new/hr

select table_name from user_tables;
```



_If Drop New schema:_
```
conn /as sysdba

DROP USER hr_new CASCADE;
```





#### 4. Remap Table:


```
conn hr/hr

select table_name from user_tables;

-----------------------
REGIONS
COUNTRIES
LOCATIONS
DEPARTMENTS
JOBS
EMPLOYEES
JOB_HISTORY

7 rows selected.
```


_Syntax:_
```
REMAP_TABLE=[schema.]old_tablename[.partition]:new_tablename
```


_Remap Table:_
```
impdp system/sys@orcl tables=hr.jobs remap_table=hr.jobs:jobs_new directory=expdp_dir dumpfile=hr_schema.dmp logfile=jobs_table_import.log exclude=constraint
```



```
select table_name from user_tables;

TABLE_NAME
--------------------------
REGIONS
COUNTRIES
LOCATIONS
DEPARTMENTS
JOBS
EMPLOYEES
JOB_HISTORY
JOBS_NEW

8 rows selected.
```



```
select count (*) from hr.jobs_new;

select * from hr.jobs_new;
```




_If Delete New Table:_
```
DROP TABLE hr.JOBS_NEW CASCADE CONSTRAINTS;
```





#### 5. Import Specific Table from full Schema:


##### Example-1: 
```
conn /as sysdba;

select * from hr.JOBS;
```


```
DROP TABLE hr.JOBS CASCADE CONSTRAINTS;
```


```
conn hr/hr

select table_name from user_tables;

TABLE_NAME
------------------------
REGIONS
COUNTRIES
LOCATIONS
DEPARTMENTS
EMPLOYEES
JOB_HISTORY

6 rows selected.
```



```
impdp system/password@orcl tables=hr.jobs directory=expdp_dir dumpfile=hr_schema.dmp logfile=jobs_tables_import.log
```



```
conn hr/hr

select table_name from user_tables;

TABLE_NAME
---------------------------
REGIONS
COUNTRIES
LOCATIONS
DEPARTMENTS
EMPLOYEES
JOB_HISTORY
JOBS

7 rows selected.
```




##### Example-2: Import Specific Table with Remap: 

```
conn /as sysdba;

select * from hr_new.JOBS;
```


```
DROP TABLE hr_new.JOBS CASCADE CONSTRAINTS;
```


```
conn hr_new/hr

select table_name from user_tables;

TABLE_NAME
------------------------
COUNTRIES
DEPARTMENTS
EMPLOYEES
LOCATIONS
REGIONS
JOB_HISTORY

6 rows selected.
```



_Import `jobs` table into `hr_new` schema:_
```
impdp system/password@orcl tables=hr.jobs remap_schema=hr:hr_new directory=expdp_dir dumpfile=hr_schema.dmp logfile=jobs_tables_import.log
```


```
conn hr_new/hr

select table_name from user_tables;

TABLE_NAME
------------------------
COUNTRIES
DEPARTMENTS
EMPLOYEES
LOCATIONS
REGIONS
JOB_HISTORY
JOBS

7 rows selected.
```




#### 6. Import Data Only: 

_Delete data from `jobs` table:_
```
truncate table hr_new.jobs drop storage;
```



```
select * from hr_new.jobs;
select count (*) from hr_new.jobs;
```


_Remap shcema and import data only:_
```
impdp system/password@orcl tables=hr.jobs remap_schema=hr:hr_new directory=expdp_dir dumpfile=hr_schema.dmp logfile=jobs_tables_import.log content=data_only 
```



#### 7. Remap Tablespace:
- Target tablespace must exist. 

_Syntax:_
```
REMAP_TABLESPACE=source_tablespace:target_tablespace
```


_Create tablespace:_
```
CREATE TABLESPACE users_new DATAFILE '/u01/oradata/users_new01.dbf' SIZE 100M AUTOEXTEND ON;
```


```
impdp system/password@orcl REMAP_TABLESPACE=users:users_new DIRECTORY=expdp_dir DUMPFILE=users_ts.dmp LOGFILE=users_ts_remap_import.log
```



### Gathering Statistics:

- It’s gathering statistics for the `SYS` and `SYSTEM` schemas.
- Statistics include:
    - Table row counts
    - Column cardinalities (distinct values)
    - Index selectivity
    - Data distribution (histograms)
    - Table and index sizes



#### Why gather stats on SYS and SYSTEM?

- Stats are automatically gathered by Oracle’s auto task job (default runs daily in maintenance window).
- But sometimes DBAs explicitly gather stats on SYS and SYSTEM if:
- The database was newly created or upgraded.
- Major changes happened in data dictionary tables (catalog, system metadata).
- Performance issues indicate stale/missing stats in these schemas.
- You want to ensure dictionary-managed SQL queries (like queries on DBA_, ALL_, USER_ views) run efficiently.




_After import Gather Statistic:_
```
begin 
    dbms_stats.gather_schema_stats('SYS')
    dbms_stats.gather_schema_stats('SYSTEM')
end;
```




### Monitor Progress:

```
SELECT * FROM dba_datapump_jobs;
SELECT * FROM dba_datapump_sessions;
```






